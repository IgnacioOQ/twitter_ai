{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ce9d1d39",
      "metadata": {
        "id": "ce9d1d39"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "env_switch_setup"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# --- REPO ROOT ON sys.path (so `from src.*` works locally) ---\n",
        "_REPO_ROOT = str(Path(os.getcwd()).resolve().parents[1])\n",
        "if _REPO_ROOT not in sys.path:\n",
        "    sys.path.insert(0, _REPO_ROOT)\n",
        "\n",
        "\n",
        "# --- ENVIRONMENT SWITCH ---\n",
        "# Set to True if running on local machine with Google Drive Desktop mounted\n",
        "# Set to False if running in Google Colab cloud\n",
        "RUNNING_LOCALLY = True\n",
        "\n",
        "if RUNNING_LOCALLY:\n",
        "    # Standard macOS path for Google Drive Desktop\n",
        "    BASE_PATH = Path('/Volumes/GoogleDrive/MyDrive/AI Public Trust')\n",
        "else:\n",
        "    # Google Colab cloud path\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_PATH = Path('/content/drive/MyDrive/AI Public Trust')\n",
        "\n",
        "# Pre-compute critical paths used across notebooks\n",
        "twits_folder = BASE_PATH / 'Raw Data/Twits/'\n",
        "test_folder = BASE_PATH / 'Raw Data/'\n",
        "datasets_folder = BASE_PATH / 'Data Sets'\n",
        "cleanedds_folder = BASE_PATH / 'Data Sets/Cleaned Data'\n",
        "networks_folder = BASE_PATH / 'Data Sets/Networks/'\n",
        "literature_folder = BASE_PATH / 'Literature/'\n",
        "topic_models_folder = BASE_PATH / 'Models/Topic Modeling/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06941e8c",
      "metadata": {
        "id": "06941e8c",
        "outputId": "0c3e24c9-2754-4f8a-c19d-7e71eddf8c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parent directory /Users/ignacioojea/Documents/Research/AI Public Trust Twitter\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "#from tweepy import Stream\n",
        "from datetime import timedelta\n",
        "import json\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "from datetime import timedelta\n",
        "import tqdm\n",
        "import pickle\n",
        "\n",
        "path = os.getcwd()\n",
        "# parent directory\n",
        "parent = os.path.dirname(path)\n",
        "print(\"Parent directory\", parent)\n",
        "source_folder = parent+'/Data/'\n",
        "twits_folder=source_folder+'Twits/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc19d4fc",
      "metadata": {
        "id": "fc19d4fc"
      },
      "outputs": [],
      "source": [
        "#BearerToken = 'AAAAAAAAAAAAAAAAAAAAALrWiAEAAAAAaNJvkshDSGyCxM2Ln%2BlbbgkXMJU%3DfVbisbZLd2JuZaeguCBzcjuU2nLtdGrqPHM9YQ5zqXrmes1gfk'\n",
        "BearerToken = 'AAAAAAAAAAAAAAAAAAAAAGrpoQEAAAAA4Uk6TBq88nyUIQoF%2B70Osv%2Fmlnc%3Dk0Y0Se1NEWbOG0xWVEuEv8eIIf2mYxlN56WnC0xRuwthQS4AkQ'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "480a6c09",
      "metadata": {
        "id": "480a6c09"
      },
      "source": [
        "### Query notes\n",
        "\n",
        "- Tweet field list: https://developer.twitter.com/en/docs/twitter-api/fields\n",
        "- Query logic: https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
        "- Time converter: https://www.timestamp-converter.com/\n",
        "- AI TIMELINE: https://lifearchitect.ai/timeline/\n",
        "- https://docs.tweepy.org/en/stable/examples.html\n",
        "- https://docs.tweepy.org/en/stable/expansions_and_fields.html\n",
        "\n",
        "### Helpful data:\n",
        "- https://twittercommunity.com/t/client-search-all-tweets-returns-only-default-fields/179008/4\n",
        "- https://twittercommunity.com/top?period=weekly\n",
        "\n",
        "### Mas notas al final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63531285",
      "metadata": {
        "id": "63531285"
      },
      "outputs": [],
      "source": [
        "query = '(ChatGPT OR Chat-GPT OR GPT OR GPT-3 OR GPT3 OR GPT-4 OR GPT4 OR BARD OR (Bing AI) OR LLMs OR LLM OR AI OR AGI OR (artificial intelligence) OR (large language models) OR LaMDA OR PaLM OR Med-PaLM OR BERT OR LLaMA) lang:en'\n",
        "start_time = datetime.datetime(2022,11,15,0,0,0)\n",
        "# 10 mins windows\n",
        "step_size = 600\n",
        "step_time = start_time+timedelta(seconds=step_size)\n",
        "limit=2000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74adc49d",
      "metadata": {
        "id": "74adc49d"
      },
      "source": [
        "## Trying it out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed0dc1ed",
      "metadata": {
        "id": "ed0dc1ed"
      },
      "outputs": [],
      "source": [
        "tryit = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36754a67",
      "metadata": {
        "id": "36754a67"
      },
      "outputs": [],
      "source": [
        "if tryit:# Client with bearer token\n",
        "    client = tweepy.Client(bearer_token=BearerToken,\n",
        "                            return_type = dict,\n",
        "                           #return_type='response',\n",
        "                            wait_on_rate_limit=False)\n",
        "\n",
        "\n",
        "    paginator = tweepy.Paginator(client.search_all_tweets,\n",
        "                                        query=query,\n",
        "                                        # https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet\n",
        "                                        tweet_fields=['id','entities', 'created_at',\n",
        "                                                    'author_id','text',\n",
        "                                                    'public_metrics',\n",
        "                                                    'possibly_sensitive',\n",
        "                                                    'conversation_id',\n",
        "                                                    'referenced_tweets',\n",
        "                                                    'lang',\n",
        "                                                    #'non_public_metrics',\n",
        "                                                    #'organic_metrics',\n",
        "                                                    #'promoted_metrics',\n",
        "                                                   ],\n",
        "                                      user_fields=['id','name','username','created_at','public_metrics','verified',\n",
        "                                                   'description','entities','location'],\n",
        "                                  expansions=['author_id','referenced_tweets.id','referenced_tweets.id.author_id'],\n",
        "                                        start_time=start_time,\n",
        "                                        end_time=step_time,\n",
        "                                        max_results=500,\n",
        "                                        limit=limit)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac991dc6",
      "metadata": {
        "id": "ac991dc6"
      },
      "source": [
        "https://github.com/tweepy/tweepy/pull/1861\n",
        "https://github.com/tweepy/tweepy/issues/1843"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4054244c",
      "metadata": {
        "id": "4054244c",
        "outputId": "0864e284-f66e-4c12-f2c0-864452273b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The paginator object is of type: <class 'tweepy.pagination.Paginator'>\n",
            "---------------\n",
            "Lets briefly study the objects we have at hand:\n"
          ]
        },
        {
          "ename": "Forbidden",
          "evalue": "403 Forbidden\nWhen authenticating requests to the Twitter API v2 endpoints, you must use keys and tokens from a Twitter developer App that is attached to a Project. You can create a project via the developer portal.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLets briefly study the objects we have at hand:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m paginator:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------- page object type ------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(page))\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tweepy/pagination.py:126\u001b[0m, in \u001b[0;36mPaginationIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpagination_token\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pagination_token\n\u001b[0;32m--> 126\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, Response):\n\u001b[1;32m    129\u001b[0m     meta \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmeta\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tweepy/client.py:1163\u001b[0m, in \u001b[0;36mClient.search_all_tweets\u001b[0;34m(self, query, **params)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"search_all_tweets( \\\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m    query, *, end_time=None, expansions=None, max_results=None, \\\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03m    media_fields=None, next_token=None, place_fields=None, \\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;124;03m.. _pagination: https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/paginate\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m-> 1163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/2/tweets/search/all\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend_time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpansions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedia.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnext_token\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplace.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpoll.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msince_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msort_order\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstart_time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtweet.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muntil_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTweet\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tweepy/client.py:129\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[0;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_request\u001b[39m(\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, route, params\u001b[38;5;241m=\u001b[39m{}, endpoint_parameters\u001b[38;5;241m=\u001b[39m(), json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_auth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    126\u001b[0m ):\n\u001b[1;32m    127\u001b[0m     request_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[0;32m--> 129\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_auth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_type \u001b[38;5;129;01mis\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tweepy/client.py:100\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[0;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(response)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Forbidden(response)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFound(response)\n",
            "\u001b[0;31mForbidden\u001b[0m: 403 Forbidden\nWhen authenticating requests to the Twitter API v2 endpoints, you must use keys and tokens from a Twitter developer App that is attached to a Project. You can create a project via the developer portal."
          ]
        }
      ],
      "source": [
        "if tryit:\n",
        "    print('The paginator object is of type: '+ str(type(paginator)))\n",
        "\n",
        "    print('---------------')\n",
        "    print('Lets briefly study the objects we have at hand:')\n",
        "    for page in paginator:\n",
        "        print('--------------- page object type ------------')\n",
        "        print(type(page))\n",
        "        rare_object = page\n",
        "        #print(page.data)                       # The tweets are here\n",
        "        #print(page.meta)\n",
        "        #print(page.includes)                   # The includes are here\n",
        "        print('--------------- exploring the data ------------')\n",
        "        data = page['data']\n",
        "        print(type(data))\n",
        "        print(len(data))\n",
        "        print(type(data[0]))\n",
        "        print(data[0]['text'])\n",
        "        print(data[0]['created_at'])\n",
        "        print('--------------- exploring the extensions ------------')\n",
        "        includes = page['includes']\n",
        "        print(type(includes))\n",
        "        print(includes.keys())\n",
        "        print(type(includes['tweets']))\n",
        "        print(len(includes['tweets']))\n",
        "        print(len(includes['users']))\n",
        "        print('--------------- exploring the meta ------------')\n",
        "        meta = page['meta']\n",
        "        print(meta)\n",
        "        break\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03f2c077",
      "metadata": {
        "id": "03f2c077"
      },
      "outputs": [],
      "source": [
        "if tryit:\n",
        "    file_name = 'testing.json'\n",
        "    dict_list = []\n",
        "    out_file = open(source_folder+file_name, \"w\",encoding='utf-8')\n",
        "\n",
        "    for page in paginator:\n",
        "        dict_list.append(page)\n",
        "    json.dump(dict_list, out_file, indent = 1)\n",
        "\n",
        "    out_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f113103d",
      "metadata": {
        "id": "f113103d"
      },
      "outputs": [],
      "source": [
        "if tryit:\n",
        "    f = open(source_folder+\"testing.json\",'r',encoding='utf-8')\n",
        "    test = json.load(f)\n",
        "    f.close()\n",
        "    print('Remember we set the requests limit to '+str(limit)+'.')\n",
        "    print('While the total requests found were of '+str(len(test))+'.')\n",
        "    print('Also we set the max per request at 500, and the data has more or less '+str(len(test[0]['data']))+' twits per request'+'.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887e504b",
      "metadata": {
        "id": "887e504b"
      },
      "outputs": [],
      "source": [
        "if tryit:\n",
        "    index=0\n",
        "    for twit in test[0]['data']:\n",
        "        #index+=1\n",
        "        try:\n",
        "            type_of_ref=twit['referenced_tweets'][0]['type']\n",
        "            #if type_of_ref=='replied_to':\n",
        "            print(type_of_ref)\n",
        "            #print(twit['referenced_tweets'][0]['id'])\n",
        "            #print(test[0]['includes']['tweets'][index]['id'])\n",
        "            print(test[0]['includes']['tweets'][index]['id']==twit['referenced_tweets'][0]['id'])\n",
        "            index+=1\n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62445636",
      "metadata": {
        "id": "62445636"
      },
      "outputs": [],
      "source": [
        "if tryit:\n",
        "    count = 0\n",
        "    for i in range(len(test)):\n",
        "        for j in range(len(test[i]['data'])):\n",
        "            count+=1\n",
        "            print(test[i]['data'][j]['text'])\n",
        "            print('-----')\n",
        "            if count>5:\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df03875b",
      "metadata": {
        "id": "df03875b"
      },
      "source": [
        "# Now the Actual Job"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09ca259a",
      "metadata": {
        "id": "09ca259a"
      },
      "source": [
        "## Time windows\n",
        "\n",
        "Following this timeline: https://lifearchitect.ai/timeline/\n",
        "\n",
        "ChatGPT was released November 30th 2022. We start the scraping on November 15."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acf9b835",
      "metadata": {
        "id": "acf9b835"
      },
      "source": [
        "## Define the proper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a6d1d07",
      "metadata": {
        "id": "0a6d1d07"
      },
      "outputs": [],
      "source": [
        "query = '(ChatGPT OR Chat-GPT OR GPT OR GPT-3 OR GPT3 OR GPT-4 OR GPT4 OR BARD OR (Bing AI) OR LLMs OR LLM OR AI OR AGI OR (artificial intelligence) OR (large language models) OR LaMDA OR PaLM OR Med-PaLM OR BERT OR LLaMA) lang:en'\n",
        "limit=2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98b3064",
      "metadata": {
        "id": "f98b3064"
      },
      "outputs": [],
      "source": [
        "# Client with bearer token\n",
        "# https://docs.tweepy.org/en/stable/client.html\n",
        "client = tweepy.Client(bearer_token=BearerToken,\n",
        "                        return_type = dict,\n",
        "                        wait_on_rate_limit=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29eaece5",
      "metadata": {
        "id": "29eaece5"
      },
      "outputs": [],
      "source": [
        "def get_tweets(start_time,end_time,file_name,query=query,exec_time = False,limit=100):\n",
        "    st = time.time()\n",
        "    #print(str(datetime.datetime.now()))\n",
        "    dict_list = []\n",
        "    out_file = open(file_name, \"w\",encoding='utf-8')\n",
        "    experiment = True\n",
        "\n",
        "    try:\n",
        "        page_count=0\n",
        "        for page in tweepy.Paginator(client.search_all_tweets,\n",
        "                        query=query,\n",
        "                        # https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet\n",
        "                        tweet_fields=['id','entities', 'created_at',\n",
        "                                    'author_id','text',\n",
        "                                    'public_metrics',\n",
        "                                    'possibly_sensitive',\n",
        "                                    'conversation_id',\n",
        "                                    'referenced_tweets',\n",
        "                                    'lang',\n",
        "                                               ],\n",
        "                        user_fields=['id','name','username','created_at','public_metrics','verified',\n",
        "                                    'description','entities','location'],\n",
        "                        expansions=['author_id','referenced_tweets.id','referenced_tweets.id.author_id'],\n",
        "                                    start_time=start_time,\n",
        "                                    end_time=end_time,\n",
        "                                    max_results=500,\n",
        "                                    limit=limit):\n",
        "            time.sleep(0.75)\n",
        "            #print(str(datetime.datetime.now()))\n",
        "            page_count+=1\n",
        "            dict_list.append(page)\n",
        "        print('Total amount of pages: '+str(page_count))\n",
        "        json.dump(dict_list, out_file, indent = 1)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        #print('Maxed reached (probably). Waiting a few seconds and retrying...')\n",
        "        experiment=False\n",
        "        time.sleep(901)\n",
        "\n",
        "\n",
        "    out_file.close()\n",
        "\n",
        "    if exec_time:\n",
        "        et = time.time()\n",
        "        elapsed_time = et - st\n",
        "        print('Execution time:', elapsed_time, 'seconds')\n",
        "\n",
        "    return experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f80803d",
      "metadata": {
        "id": "5f80803d"
      },
      "source": [
        "## Create Windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358c1d84",
      "metadata": {
        "id": "358c1d84"
      },
      "outputs": [],
      "source": [
        "# Create windows\n",
        "start_time = datetime.datetime(2022,11,15,0,0,0)\n",
        "# Para empezar hagamos un mes\n",
        "end_time = datetime.datetime(2023,2,27,12,0,0)\n",
        "step_size = 1800\n",
        "\n",
        "step_time = start_time+timedelta(seconds=step_size)\n",
        "prior_time = start_time\n",
        "windows = []\n",
        "while step_time<=end_time:\n",
        "    windows.append([prior_time,step_time])\n",
        "    prior_time = step_time\n",
        "    step_time = step_time+timedelta(seconds=step_size)\n",
        "\n",
        "windows[-1]\n",
        "#datetime.datetime.strftime(windows[0][0],\"%Y-%m-%dT%H:%M:%S.%fZ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b961fdf",
      "metadata": {
        "id": "5b961fdf"
      },
      "source": [
        "## Test the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b47463b1",
      "metadata": {
        "id": "b47463b1"
      },
      "outputs": [],
      "source": [
        "file_name = source_folder+'tweets_test.json'\n",
        "tryit=False\n",
        "if tryit:\n",
        "    start_time,end_time = windows[0][0],windows[0][1]\n",
        "    experiment=get_tweets(start_time,end_time,file_name,exec_time=False, limit=limit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c1b52bf",
      "metadata": {
        "id": "8c1b52bf"
      },
      "outputs": [],
      "source": [
        "f = open(file_name,'r',encoding='utf-8')\n",
        "test = json.load(f)\n",
        "f.close()\n",
        "print('Remember we set the requests limit to '+str(2000)+'.')\n",
        "print('While the total requests found were of '+str(len(test))+'.')\n",
        "print('Also we set the max per request at 500, and the data has more or less '+str(len(test[0]['data']))+' twits per request'+'.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30997806",
      "metadata": {
        "id": "30997806"
      },
      "source": [
        "## Doing the job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5547813",
      "metadata": {
        "id": "d5547813"
      },
      "outputs": [],
      "source": [
        "# Load processed windows\n",
        "with open('processed_windows_list', 'rb') as fp:\n",
        "    processed_windows = pickle.load(fp)\n",
        "processed_windows[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf7298f4",
      "metadata": {
        "id": "cf7298f4"
      },
      "outputs": [],
      "source": [
        "for i in range(len(windows)):\n",
        "    if windows[i] not in processed_windows:\n",
        "        print(i)\n",
        "        print(windows[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a78687",
      "metadata": {
        "id": "c2a78687"
      },
      "outputs": [],
      "source": [
        "# Get data\n",
        "st = time.time()\n",
        "\n",
        "attempts = 0\n",
        "successes = 0\n",
        "failures = 0\n",
        "for i in range(len(windows)):\n",
        "    if windows[i] not in processed_windows:\n",
        "        start_time,end_time = windows[i][0],windows[i][1]\n",
        "        left_window = datetime.datetime.strftime(windows[i][0],\"%Y-%m-%dT%H:%M:%S\")\n",
        "        right_window= datetime.datetime.strftime(windows[i][1],\"%Y-%m-%dT%H:%M:%S\")\n",
        "        file_name = twits_folder+'tweets_'+left_window+'.json'\n",
        "        experiment = False\n",
        "        while not experiment:\n",
        "            attempts+=1\n",
        "            experiment=get_tweets(start_time,end_time,file_name,exec_time=False, limit=limit)\n",
        "            print(windows[i])\n",
        "            if experiment == False:\n",
        "                failures +=1\n",
        "                print(failures)\n",
        "            if failures > 25:\n",
        "                break\n",
        "        successes +=1\n",
        "\n",
        "        processed_windows.append([start_time,end_time])\n",
        "        with open('processed_windows_list', 'wb') as fp:\n",
        "            pickle.dump(processed_windows, fp)\n",
        "\n",
        "        if failures > 25:\n",
        "            print('This is the last window that worked:')\n",
        "            print(windows[i-1])\n",
        "            break\n",
        "\n",
        "print(successes/attempts)\n",
        "\n",
        "et = time.time()\n",
        "elapsed_time = et - st\n",
        "print('Execution time:', elapsed_time/60, 'minutes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "550525a3",
      "metadata": {
        "id": "550525a3"
      },
      "outputs": [],
      "source": [
        "failures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580b2556",
      "metadata": {
        "id": "580b2556"
      },
      "outputs": [],
      "source": [
        "with open('processed_windows_list', 'rb') as fp:\n",
        "    processed_windows = pickle.load(fp)\n",
        "processed_windows[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fefd2b2",
      "metadata": {
        "id": "1fefd2b2"
      },
      "source": [
        "## Notas\n",
        "\n",
        "#### Return type = 'response'\n",
        "\n",
        "- https://docs.tweepy.org/en/stable/response.html#tweepy.Response\n",
        "\n",
        "Type of object: collections.namedtuple\n",
        "\n",
        "- https://docs.python.org/3/library/collections.html#collections.namedtuple\n",
        "- https://www.geeksforgeeks.org/namedtuple-in-python/\n",
        "\n",
        "### IMPORTANTE: Es un problema con el flatten! (por eso no uso flatten ahora)\n",
        "\n",
        "- https://docs.tweepy.org/en/stable/faq.html\n",
        "\n",
        "Ahi dice:\n",
        "\n",
        "How do I access includes data while using Paginator?\n",
        "Paginator.flatten() flattens the data and iterates over each object.\n",
        "\n",
        "To access includes, you’ll need to iterate through each response instead.\n",
        "\n",
        "\n",
        "- https://stackoverflow.com/questions/73196236/tweepy-error-using-paginator-to-extract-media-data\n",
        "- https://www.firebolt.io/glossary-items/data-flattening-and-data-unflattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87adf9f",
      "metadata": {
        "id": "e87adf9f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61abe7a9",
      "metadata": {
        "id": "61abe7a9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
